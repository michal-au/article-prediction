{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Xgboosted trees as feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "PROJECT_DIR = '/home/michal/diplomka/code'\n",
    "if PROJECT_DIR not in sys.path:\n",
    "    sys.path.append(PROJECT_DIR)\n",
    "from lib.utils import load_csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEATURES = ['a_hypernyms', 'a_head_form', 'a_head_number', 'a_non_article_det', 'a_parent', 'a_pos_after_head', 'a_pos_before_head', 'a_words_after_head', 'a_words_after_np', 'a_words_before_head', 'a_words_before_np', 'b_head_proper', 'b_head_pos_simple', 'b_object_form', 'b_pos_after_head_as_list', 'b_pos_before_head_as_list', 'b_pp_object_form', 'b_postmodification_type', 'b_referent', 'b_words_after_head_as_list', 'b_words_after_np_as_list', 'b_words_before_head_as_list', 'b_words_before_np_as_list', 'c_countability_bnc', 'd_head_form_embeddings', 'e_kenlm_ggl_5_lc_nbs']\n",
    "DATA_PATH = os.path.join(PROJECT_DIR, '../data/features/penn/postprocessed')\n",
    "MODEL_PATH = os.path.join(PROJECT_DIR, '../data/model/xgboost_with_logreg')\n",
    "CV_RESULTS_LOG_PATH = os.path.join(PROJECT_DIR, 'logs/experiments/model_results/penn/xgboost-with-logreg')  # logovani vysledku z cross-validace\n",
    "NUM_CLASS = 3\n",
    "TRAIN_SET_NAME = 'train'\n",
    "TEST_SET_NAME = 'heldout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263088, 35516) (10076, 35516)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = load_data(FEATURES, TRAIN_SET_NAME)\n",
    "test_x, test_y = load_data(FEATURES, TEST_SET_NAME)\n",
    "assert train_x.shape[1] == test_x.shape[1]\n",
    "print(train_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_y)\n",
    "train_y = le.transform(train_y)\n",
    "test_y = le.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XGB_DEFAULT_PARAMS = { \n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 2000,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'multi:softmax',\n",
    "    'nthread': 24,\n",
    "    'scale_pos_weight': 1,\n",
    "    'seed': 27\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(features, dataset_name, sample=None):\n",
    "    y = np.load(os.path.join(DATA_PATH, dataset_name, 'Y_article'))\n",
    "    if sample:\n",
    "        np.random.seed(seed=42)\n",
    "        sample_indices = [np.random.choice(len(y), sample, replace=False)]\n",
    "        y = y[sample_indices]\n",
    "        \n",
    "    feature_matrices = []\n",
    "    for feature_name in features:\n",
    "        feature_matrix = load_csr_matrix(\n",
    "            os.path.join(DATA_PATH, dataset_name, feature_name + '.npz')\n",
    "        )\n",
    "        if sample:\n",
    "            feature_matrix = scipy.sparse.csr_matrix(feature_matrix.toarray()[sample_indices])\n",
    "        feature_matrices.append(feature_matrix)\n",
    "    x =  scipy.sparse.hstack(feature_matrices)\n",
    "    assert x.shape[0] == len(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_save(model, xgb_train_x, xgb_train_y, save_file_name):\n",
    "    start_time = time.time()\n",
    "    model.fit(xgb_train_x, xgb_train_y)\n",
    "    pickle.dump(model, open(os.path.join(MODEL_PATH, save_file_name), 'wb'))\n",
    "    end_time = time.time()\n",
    "    print(\"Done in {} minutes\".format((end_time - start_time)/60))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x_20000, train_y_20000 = load_data(FEATURES, TRAIN_SET_NAME, sample=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 35516) 10000\n",
      "(10000, 35516) 10000\n"
     ]
    }
   ],
   "source": [
    "train_x_20000_ = train_x_20000.toarray()\n",
    "train_x_a, train_y_a = scipy.sparse.csr_matrix(train_x_20000_[:10000]), train_y_20000[:10000]\n",
    "train_x_b, train_y_b = scipy.sparse.csr_matrix(train_x_20000_[10000:]), train_y_20000[10000:]\n",
    "print(train_x_a.shape, len(train_y_a))\n",
    "print(train_x_b.shape, len(train_y_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_ensemble(xgb_model, logreg_model, xgb_train_x, xgb_train_y, logreg_train_x, logreg_train_y, model_name):\n",
    "    xgb_model = train_and_save(xgb_model, xgb_train_x, xgb_train_y, save_file_name='xgboost_'+model_name+'.model')\n",
    "    logreg_train_x = xgb_model.booster().predict(xgb.DMatrix(logreg_train_x), pred_leaf=True)\n",
    "    train_and_save(logreg_model, logreg_train_x, logreg_train_y, save_file_name='xgbWithLogreg_'+model_name+'.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_ensemble(model_name, test_x, test_y):\n",
    "    xgb_model = pickle.load(open(os.path.join(MODEL_PATH, 'xgboost_'+model_name+'.model'), \"rb\"))\n",
    "    xgblogreg_model = pickle.load(open(os.path.join(MODEL_PATH, 'xgbWithLogreg_'+model_name+'.model'), \"rb\"))\n",
    "    test_predictions = xgblogreg_model.predict(xgb_model.booster().predict(xgb.DMatrix(test_x), pred_leaf=True))\n",
    "    xgb_test_predictions = xgb_model.predict(test_x)\n",
    "    print(\"Accuracy ({}): {:.4f}\\n\".format(TEST_SET_NAME, metrics.accuracy_score(test_y, test_predictions)))\n",
    "    print(\"Accuracy xgb ({}): {:.4f}\\n\".format(TEST_SET_NAME, metrics.accuracy_score(test_y, xgb_test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0.6854831536610921 minutes\n",
      "Done in 3.101623260974884 minutes\n"
     ]
    }
   ],
   "source": [
    "model_params = {'n_estimators': 162, 'max_depth':9, 'min_child_weight':1, 'gamma':0.1, 'subsample':1, 'colsample_bytree':0.8}\n",
    "xgb_model = XGBClassifier(**dict(XGB_DEFAULT_PARAMS, **model_params, nthread=8))\n",
    "logreg_model = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n",
    "train_ensemble(xgb_model, logreg_model, train_x_a, train_y_a, train_x_b, train_y_b, '010_000_separate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (heldout): 0.8385\n",
      "\n",
      "Accuracy xgb (heldout): 0.8635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_ensemble('010_000_separate', test_x, le.inverse_transform(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 35516) 20000\n",
      "(20000, 35516) 20000\n",
      "Done in 1.4325003147125244 minutes\n",
      "Done in 12.9325422167778 minutes\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = load_data(FEATURES, TRAIN_SET_NAME, sample=40000)\n",
    "train_x = train_x.toarray()\n",
    "train_x_a, train_y_a = scipy.sparse.csr_matrix(train_x[:20000]), train_y[:20000]\n",
    "train_x_b, train_y_b = scipy.sparse.csr_matrix(train_x[20000:]), train_y[20000:]\n",
    "print(train_x_a.shape, len(train_y_a))\n",
    "print(train_x_b.shape, len(train_y_b))\n",
    "model_params = {'n_estimators': 198, 'max_depth':7, 'min_child_weight':1, 'gamma': 0.4, 'subsample':0.9, 'colsample_bytree':1}\n",
    "xgb_model = XGBClassifier(**dict(XGB_DEFAULT_PARAMS, **model_params, nthread=8))\n",
    "logreg_model = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n",
    "train_ensemble(xgb_model, logreg_model, train_x_a, train_y_a, train_x_b, train_y_b, '020_000_separate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (heldout): 0.8553\n",
      "\n",
      "Accuracy xgb (heldout): 0.8750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_ensemble('020_000_separate', test_x, le.inverse_transform(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 35516) 50000\n",
      "(50000, 35516) 50000\n",
      "Done in 7.208277940750122 minutes\n",
      "Done in 41.59245844284693 minutes\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = load_data(FEATURES, TRAIN_SET_NAME, sample=100000)\n",
    "train_x = train_x.toarray()\n",
    "train_x_a, train_y_a = scipy.sparse.csr_matrix(train_x[:50000]), train_y[:50000]\n",
    "train_x_b, train_y_b = scipy.sparse.csr_matrix(train_x[50000:]), train_y[50000:]\n",
    "print(train_x_a.shape, len(train_y_a))\n",
    "print(train_x_b.shape, len(train_y_b))\n",
    "model_params = {'n_estimators': 354, 'max_depth':9, 'min_child_weight':1, 'gamma':0, 'subsample':0.9, 'colsample_bytree':1}\n",
    "xgb_model = XGBClassifier(**dict(XGB_DEFAULT_PARAMS, **model_params, nthread=8))\n",
    "logreg_model = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n",
    "train_ensemble(xgb_model, logreg_model, train_x_a, train_y_a, train_x_b, train_y_b, '050_000_separate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (heldout): 0.8632\n",
      "\n",
      "Accuracy xgb (heldout): 0.8944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_ensemble('050_000_separate', test_x, le.inverse_transform(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 35516) 100000\n",
      "(100000, 35516) 100000\n",
      "Done in 12.540844289461772 minutes\n",
      "Done in 69.7520286043485 minutes\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = load_data(FEATURES, TRAIN_SET_NAME, sample=200000)\n",
    "train_x = train_x.toarray()\n",
    "train_x_a, train_y_a = scipy.sparse.csr_matrix(train_x[:100000]), train_y[:100000]\n",
    "train_x_b, train_y_b = scipy.sparse.csr_matrix(train_x[100000:]), train_y[100000:]\n",
    "print(train_x_a.shape, len(train_y_a))\n",
    "print(train_x_b.shape, len(train_y_b))\n",
    "model_params = {'n_estimators': 487, 'max_depth':9, 'min_child_weight':1, 'gamma':0.1, 'subsample':0.8, 'colsample_bytree':1}\n",
    "xgb_model = XGBClassifier(**dict(XGB_DEFAULT_PARAMS, **model_params, nthread=8))\n",
    "logreg_model = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n",
    "train_ensemble(xgb_model, logreg_model, train_x_a, train_y_a, train_x_b, train_y_b, '100_000_separate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (heldout): 0.8769\n",
      "\n",
      "Accuracy xgb (heldout): 0.9023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_ensemble('100_000_separate', test_x, le.inverse_transform(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0.7081761916478475 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0.1, learning_rate=0.1, max_delta_step=0, max_depth=9,\n",
       "       min_child_weight=1, missing=None, n_estimators=162, nthread=8,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=27, silent=True, subsample=1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = {'n_estimators': 162, 'max_depth':9, 'min_child_weight':1, 'gamma':0.1, 'subsample':1, 'colsample_bytree':0.8}\n",
    "xgb_model = XGBClassifier(**dict(XGB_DEFAULT_PARAMS, **model_params, nthread=8))\n",
    "train_and_save(xgb_model, train_x_a, le.transform(train_y_a), save_file_name='xgboost_010_000.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbmatrix_train_x_b = xgb.DMatrix(train_x_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbmatrix_test_x = xgb.DMatrix(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_model = pickle.load(open(os.path.join(MODEL_PATH, 'xgboost_010_000.model'), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 1.4778326869010925 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logregmodel = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n",
    "train_and_save(logregmodel, train_x_b, le.transform(train_y_b), save_file_name='logreg_010_000.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg_model = pickle.load(open(os.path.join(MODEL_PATH, 'logreg_010_000.model'), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x_b_new = xgb_model.booster().predict(xgbmatrix_train_x_b, pred_leaf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 2.7609941085179646 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgblogreg_model = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n",
    "train_and_save(xgblogreg_model, train_x_b_new, le.transform(train_y_b), save_file_name='xgbWithLogreg_010_000.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgblogreg_model = pickle.load(open(os.path.join(MODEL_PATH, 'xgbWithLogreg_010_000.model'), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (heldout): 0.8564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = logreg_model.predict(test_x)\n",
    "print(\"Accuracy ({}): {:.4f}\\n\".format(TEST_SET_NAME, metrics.accuracy_score(test_y, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (heldout): 0.8635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = xgb_model.predict(test_x)\n",
    "print(\"Accuracy ({}): {:.4f}\\n\".format(TEST_SET_NAME, metrics.accuracy_score(test_y, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (heldout): 0.8387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = xgblogreg_model.predict(xgb_model.booster().predict(xgbmatrix_test_x, pred_leaf=True))\n",
    "print(\"Accuracy ({}): {:.4f}\\n\".format(TEST_SET_NAME, metrics.accuracy_score(test_y, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
